{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SGN\n",
    "#Importing the required libraries\n",
    "import tweepy\n",
    "from tweepy.auth import OAuthHandler\n",
    "import json\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize, pos_tag, pos_tag_sents\n",
    "\n",
    "\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud, STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the Variables\n",
    "APP_KEY = 'lXMh6z51CYTalPJo4Faf8yXW3'\n",
    "APP_SECRET = 'fM7AEgtJt7tAaALQWJFWjgIvcD0aJpQ8eigUg609LM9QDcLEHF'\n",
    "OATH_TOKEN = '152140286-NypzIPtzPyDOvE5vWzjfI2TkjOB9Q4WJFFXGRWB7'\n",
    "OATH_TOKEN_SECRET = 'yBry40PjtELUxbCBLpKmHx983BecEtQMalwlnETkOOeDs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Keywords = [\"#Global Views\",\"#Tele Groceries\",\"#The Bakery Companies\",\n",
    "            \"#BentonDread\",\"#FreshDirect\",\n",
    "            \"#Gillette\",\"#Pepsi\",\"#Pedigree\",\n",
    "           \"#Phillips\",\"#Gift Of Love\",\"#Faber-Castell\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keywords = [\"Tele Groceries\",\"#Global Views\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = OAuthHandler(APP_KEY, APP_SECRET)\n",
    "auth.set_access_token(OATH_TOKEN, OATH_TOKEN_SECRET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetDate_prev = datetime.datetime.today()-datetime.timedelta(days=70)\n",
    "targetDate_prev = targetDate_prev.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019-11-21'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targetDate_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetDate_today = datetime.datetime.today().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = ['Tweets', 'User', 'User_statuses_count', \n",
    "                             'user_followers', 'User_location', 'User_verified',\n",
    "                             'fav_count', 'rt_count', 'tweet_date','Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.DataFrame(columns=['Tweets', 'User', 'User_statuses_count', \n",
    "                             'user_followers', 'User_location', 'User_verified',\n",
    "                             'fav_count', 'rt_count', 'tweet_date','Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream(data):\n",
    "        global df_all\n",
    "        for word in data:\n",
    "            i = 0\n",
    "            for tweet in tweepy.Cursor(api.search, q=word, count=10, lang='en',since = targetDate_prev , unitl=targetDate_today).items():\n",
    "                print(i, end='\\r')\n",
    "                df.loc[i, 'Tweets'] = tweet.text\n",
    "                df.loc[i, 'User'] = tweet.user.name\n",
    "                df.loc[i, 'User_statuses_count'] = tweet.user.statuses_count\n",
    "                df.loc[i, 'user_followers'] = tweet.user.followers_count\n",
    "                df.loc[i, 'User_location'] = tweet.user.location\n",
    "                df.loc[i, 'User_verified'] = tweet.user.verified\n",
    "                df.loc[i, 'fav_count'] = tweet.favorite_count\n",
    "                df.loc[i, 'rt_count'] = tweet.retweet_count\n",
    "                df.loc[i, 'tweet_date'] = tweet.created_at\n",
    "                df.loc[i, 'Category'] = word\n",
    "                i+=1\n",
    "                df_all = df_all.append(df)\n",
    "                if i == 100:\n",
    "                    break\n",
    "                else:\n",
    "                    pass\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream(data):\n",
    "    global df_all\n",
    "    df_all = pd.DataFrame()\n",
    "    for word in data:\n",
    "        i = 0\n",
    "        for tweet in tweepy.Cursor(api.search, q=word, count=100, lang='en',since = '2019-11-18' , unitl=targetDate_today).items():\n",
    "            print(i, end='\\r')\n",
    "            if i <= 10:\n",
    "                Tweet_dict = {'Tweets': [tweet.text],\n",
    "                                'User' : [tweet.user.name],\n",
    "                                'User_statuses_count' : [tweet.user.statuses_count],\n",
    "                                'user_followers' : [tweet.user.followers_count],\n",
    "                                'User_location' : [tweet.user.location],\n",
    "                                'User_verified': [tweet.user.verified],\n",
    "                                'fav_count':[tweet.favorite_count],\n",
    "                                'rt_count': [tweet.retweet_count],\n",
    "                                'tweet_date':[tweet.created_at],\n",
    "                                'Category': [word]}\n",
    "                df = pd.DataFrame(Tweet_dict)\n",
    "                df_all = pd.concat([df_all,df],sort=False)\n",
    "                i+=1 \n",
    "            else:\n",
    "                break\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3399\r"
     ]
    }
   ],
   "source": [
    "stream(data = Keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6861359, 10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy=df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>User</th>\n",
       "      <th>User_statuses_count</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>User_location</th>\n",
       "      <th>User_verified</th>\n",
       "      <th>fav_count</th>\n",
       "      <th>rt_count</th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Once this hits 4000 views were dropping the vi...</td>\n",
       "      <td>Wattz | #TalkAboutIt OUT NOW!</td>\n",
       "      <td>89203</td>\n",
       "      <td>1757</td>\n",
       "      <td>Norwich 🔰</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-30 13:20:12</td>\n",
       "      <td>#Global Views</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Once this hits 4000 views were dropping the vi...</td>\n",
       "      <td>Wattz | #TalkAboutIt OUT NOW!</td>\n",
       "      <td>89203</td>\n",
       "      <td>1757</td>\n",
       "      <td>Norwich 🔰</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-30 13:20:12</td>\n",
       "      <td>#Global Views</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @NtechYel: Fascinating #statistics of my #c...</td>\n",
       "      <td>Wesley Pennock</td>\n",
       "      <td>333</td>\n",
       "      <td>61</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2020-01-29 21:16:00</td>\n",
       "      <td>#Global Views</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Once this hits 4000 views were dropping the vi...</td>\n",
       "      <td>Wattz | #TalkAboutIt OUT NOW!</td>\n",
       "      <td>89203</td>\n",
       "      <td>1757</td>\n",
       "      <td>Norwich 🔰</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-30 13:20:12</td>\n",
       "      <td>#Global Views</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets  \\\n",
       "0  Once this hits 4000 views were dropping the vi...   \n",
       "0  Once this hits 4000 views were dropping the vi...   \n",
       "1  RT @NtechYel: Fascinating #statistics of my #c...   \n",
       "0  Once this hits 4000 views were dropping the vi...   \n",
       "\n",
       "                            User User_statuses_count user_followers  \\\n",
       "0  Wattz | #TalkAboutIt OUT NOW!               89203           1757   \n",
       "0  Wattz | #TalkAboutIt OUT NOW!               89203           1757   \n",
       "1                 Wesley Pennock                 333             61   \n",
       "0  Wattz | #TalkAboutIt OUT NOW!               89203           1757   \n",
       "\n",
       "     User_location User_verified fav_count rt_count           tweet_date  \\\n",
       "0       Norwich 🔰          False         0        0  2020-01-30 13:20:12   \n",
       "0       Norwich 🔰          False         0        0  2020-01-30 13:20:12   \n",
       "1  San Antonio, TX         False         0        9  2020-01-29 21:16:00   \n",
       "0       Norwich 🔰          False         0        0  2020-01-30 13:20:12   \n",
       "\n",
       "        Category  \n",
       "0  #Global Views  \n",
       "0  #Global Views  \n",
       "1  #Global Views  \n",
       "0  #Global Views  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#Sony             6249430\n",
       "#Pepsi             459619\n",
       "#Gift Of Love       84100\n",
       "#Faber-Castell      57970\n",
       "#Gillette            7921\n",
       "#Pedigree            1681\n",
       "#Global Views         589\n",
       "#FreshDirect           49\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.Category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Product_Descr = {'Category': ['#Global Views','#Tele Groceries','#The Bakery Companies', '#BentonDread', '#FreshDirect', \n",
    "                              '#Gillette','#Pepsi','#Pedigree','#Sony','#Gifts of Love','#Faber-Castell'],\n",
    "                 'Product_Category': ['Home_improvement','Grocery','Bakery','Ready_to_eat','Meat','Personal_Grooming','Drinks','Pets','Electronics','Gifts',\n",
    "                                     'Books_Stationary']}\n",
    "\n",
    "Product_Data = pd.DataFrame(Product_Descr )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Product_Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#Global Views</td>\n",
       "      <td>Home_improvement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#Tele Groceries</td>\n",
       "      <td>Grocery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#The Bakery Companies</td>\n",
       "      <td>Bakery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#BentonDread</td>\n",
       "      <td>Ready_to_eat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#FreshDirect</td>\n",
       "      <td>Meat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>#Gillette</td>\n",
       "      <td>Personal_Grooming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>#Pepsi</td>\n",
       "      <td>Drinks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>#Pedigree</td>\n",
       "      <td>Pets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>#Sony</td>\n",
       "      <td>Electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>#Gifts of Love</td>\n",
       "      <td>Gifts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>#Faber-Castell</td>\n",
       "      <td>Books_Stationary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Category   Product_Category\n",
       "0           #Global Views   Home_improvement\n",
       "1         #Tele Groceries            Grocery\n",
       "2   #The Bakery Companies             Bakery\n",
       "3            #BentonDread       Ready_to_eat\n",
       "4            #FreshDirect               Meat\n",
       "5               #Gillette  Personal_Grooming\n",
       "6                  #Pepsi             Drinks\n",
       "7               #Pedigree               Pets\n",
       "8                   #Sony        Electronics\n",
       "9          #Gifts of Love              Gifts\n",
       "10         #Faber-Castell   Books_Stationary"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Product_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6861359, 10)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging with the Item_Master Data\n",
    "\n",
    "df_all_new = pd.merge(df_all,Product_Data,how='left',on='Category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>User</th>\n",
       "      <th>User_statuses_count</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>User_location</th>\n",
       "      <th>User_verified</th>\n",
       "      <th>fav_count</th>\n",
       "      <th>rt_count</th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>Category</th>\n",
       "      <th>Product_Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Once this hits 4000 views were dropping the vi...</td>\n",
       "      <td>Wattz | #TalkAboutIt OUT NOW!</td>\n",
       "      <td>89203</td>\n",
       "      <td>1757</td>\n",
       "      <td>Norwich 🔰</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-30 13:20:12</td>\n",
       "      <td>#Global Views</td>\n",
       "      <td>Home_improvement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Once this hits 4000 views were dropping the vi...</td>\n",
       "      <td>Wattz | #TalkAboutIt OUT NOW!</td>\n",
       "      <td>89203</td>\n",
       "      <td>1757</td>\n",
       "      <td>Norwich 🔰</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-30 13:20:12</td>\n",
       "      <td>#Global Views</td>\n",
       "      <td>Home_improvement</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets  \\\n",
       "0  Once this hits 4000 views were dropping the vi...   \n",
       "1  Once this hits 4000 views were dropping the vi...   \n",
       "\n",
       "                            User User_statuses_count user_followers  \\\n",
       "0  Wattz | #TalkAboutIt OUT NOW!               89203           1757   \n",
       "1  Wattz | #TalkAboutIt OUT NOW!               89203           1757   \n",
       "\n",
       "  User_location User_verified fav_count rt_count           tweet_date  \\\n",
       "0    Norwich 🔰          False         0        0  2020-01-30 13:20:12   \n",
       "1    Norwich 🔰          False         0        0  2020-01-30 13:20:12   \n",
       "\n",
       "        Category  Product_Category  \n",
       "0  #Global Views  Home_improvement  \n",
       "1  #Global Views  Home_improvement  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_new.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_all_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(tweet):\n",
    "    return ' '.join(re.sub('(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)', ' ', tweet).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tweets'] = df['Tweets'].apply(lambda x: clean_tweet(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_up(tweet_df):\n",
    "       \n",
    "#     ###---------->Inital Text Pre-Processing\n",
    "#     tweet_df['clean_tweet'] = tweet_df['Tweets'].str.replace('[^a-zA-Z\\s\\$\\%\\.]','')\n",
    "#     tweet_df['clean_tweet'] = tweet_df['clean_tweet'].apply(lambda x: \" \".join(x.lower() for x in x.split())) \n",
    "#     operators = set(('and', 'or', 'not','but'))\n",
    "#     stop = set(stopwords.words('english')) - operators\n",
    "#     tweet_df['clean_tweet']  =  tweet_df['clean_tweet'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "    \n",
    "#     ###----------> Lemmatization \n",
    "#     lem = WordNetLemmatizer()\n",
    "#     tweet_df['clean_tweet']  = tweet_df.apply(lambda row: lem.lemmatize(row['Tweets']),axis = 1)\n",
    "    \n",
    "#      ###----------> Tokenization and Part of Speech Tagging to all words in the reviews \n",
    "#     tweet_df['clean_tweet'] = pos_tag_sents(tweet_df['clean_tweet'].apply(word_tokenize).tolist())\n",
    "    \n",
    "#     return tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_up(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>User</th>\n",
       "      <th>User_statuses_count</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>User_location</th>\n",
       "      <th>User_verified</th>\n",
       "      <th>fav_count</th>\n",
       "      <th>rt_count</th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT A 160 set of 120 Faber Castell colored pencils</td>\n",
       "      <td>John HOTUJEC ™  🌈 🍒</td>\n",
       "      <td>115840</td>\n",
       "      <td>688</td>\n",
       "      <td>Kansas City, MO</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-30 09:04:05</td>\n",
       "      <td>#Faber-Castell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A 160 set of 120 Faber Castell colored pencils</td>\n",
       "      <td>Brady Barnhart</td>\n",
       "      <td>6002</td>\n",
       "      <td>15849</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>False</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-30 09:01:41</td>\n",
       "      <td>#Faber-Castell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>That one is a Faber Castell Polychromos</td>\n",
       "      <td>Sara Rhys, illustrator</td>\n",
       "      <td>4442</td>\n",
       "      <td>1948</td>\n",
       "      <td>Nomad, currently in Somerset</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-30 08:58:00</td>\n",
       "      <td>#Faber-Castell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ini pake faber castell yang classic</td>\n",
       "      <td>shafira sayang hualian</td>\n",
       "      <td>36270</td>\n",
       "      <td>771</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-30 08:07:20</td>\n",
       "      <td>#Faber-Castell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FOR SALE A series of Anemone Pavonina undertak...</td>\n",
       "      <td>Mike Bingham</td>\n",
       "      <td>3416</td>\n",
       "      <td>108</td>\n",
       "      <td>Hull, East Yorkshire, England</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-30 07:34:34</td>\n",
       "      <td>#Faber-Castell</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets                    User  \\\n",
       "0  RT A 160 set of 120 Faber Castell colored pencils     John HOTUJEC ™  🌈 🍒   \n",
       "1     A 160 set of 120 Faber Castell colored pencils          Brady Barnhart   \n",
       "2            That one is a Faber Castell Polychromos  Sara Rhys, illustrator   \n",
       "3                Ini pake faber castell yang classic  shafira sayang hualian   \n",
       "4  FOR SALE A series of Anemone Pavonina undertak...            Mike Bingham   \n",
       "\n",
       "  User_statuses_count user_followers                  User_location  \\\n",
       "0              115840            688                Kansas City, MO   \n",
       "1                6002          15849                    Seattle, WA   \n",
       "2                4442           1948   Nomad, currently in Somerset   \n",
       "3               36270            771                      Indonesia   \n",
       "4                3416            108  Hull, East Yorkshire, England   \n",
       "\n",
       "  User_verified fav_count rt_count           tweet_date        Category  \n",
       "0         False         0        2  2020-01-30 09:04:05  #Faber-Castell  \n",
       "1         False        27        2  2020-01-30 09:01:41  #Faber-Castell  \n",
       "2         False         1        0  2020-01-30 08:58:00  #Faber-Castell  \n",
       "3         False         0        0  2020-01-30 08:07:20  #Faber-Castell  \n",
       "4         False         0        0  2020-01-30 07:34:34  #Faber-Castell  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(tweet):\n",
    "    analysis = TextBlob(tweet)\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 'Positive'\n",
    "    elif analysis.sentiment.polarity ==0:\n",
    "        return 'Neutral'\n",
    "    else:\n",
    "        return 'Negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment_polarity(tweet):\n",
    "    analysis = TextBlob(tweet)\n",
    "    return analysis.sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment_subjectivity(tweet):\n",
    "    analysis = TextBlob(tweet)\n",
    "    return analysis.sentiment.subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Sentiment'] = df['Tweets'].apply(lambda x: analyze_sentiment(x))\n",
    "# df['Sentiment_Polarity'] = df['Tweets'].apply(lambda x: analyze_sentiment_polarity(x))\n",
    "# df['Sentiment_Subjectivity'] = df['Tweets'].apply(lambda x: analyze_sentiment_subjectivity(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sentiment_Polarity'] = df['Tweets'].apply(lambda x: analyze_sentiment_polarity(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sentiment_Subjectivity'] = df['Tweets'].apply(lambda x: analyze_sentiment_subjectivity(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nouns = []\n",
    "# for i in range(df['clean_tweet'].size):\n",
    "#     nouns.append([])\n",
    "#     for j in range(len(df.loc[i, 'clean_tweet'])):\n",
    "#         if (df.loc[i, 'clean_tweet'][j][1] == 'NN' or\n",
    "#                 df.loc[i, 'clean_tweet'][j][1] == 'NNS' or\n",
    "#                 df.loc[i, 'clean_tweet'][j][1] == 'NNP' or\n",
    "#                 df.loc[i, 'clean_tweet'][j][1] == 'NNPS' or\n",
    "#                 df.loc[i, 'clean_tweet'][j][1] == 'JJ' or\n",
    "#                 df.loc[i, 'clean_tweet'][j][1] == 'VB'):\n",
    "#                 nouns[i].append(df.loc[i, 'clean_tweet'][j])\n",
    "\n",
    "                \n",
    "# df['tweets_pos'] = nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>User</th>\n",
       "      <th>User_statuses_count</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>User_location</th>\n",
       "      <th>User_verified</th>\n",
       "      <th>fav_count</th>\n",
       "      <th>rt_count</th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>Category</th>\n",
       "      <th>Product_Category</th>\n",
       "      <th>Sentiment_Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Once this hits 4000 views were dropping the vi...</td>\n",
       "      <td>Wattz | #TalkAboutIt OUT NOW!</td>\n",
       "      <td>89203</td>\n",
       "      <td>1757</td>\n",
       "      <td>Norwich 🔰</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-30 13:20:12</td>\n",
       "      <td>#Global Views</td>\n",
       "      <td>Home_improvement</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Once this hits 4000 views were dropping the vi...</td>\n",
       "      <td>Wattz | #TalkAboutIt OUT NOW!</td>\n",
       "      <td>89203</td>\n",
       "      <td>1757</td>\n",
       "      <td>Norwich 🔰</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-30 13:20:12</td>\n",
       "      <td>#Global Views</td>\n",
       "      <td>Home_improvement</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT Fascinating statistics of my content global...</td>\n",
       "      <td>Wesley Pennock</td>\n",
       "      <td>333</td>\n",
       "      <td>61</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2020-01-29 21:16:00</td>\n",
       "      <td>#Global Views</td>\n",
       "      <td>Home_improvement</td>\n",
       "      <td>0.140625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Once this hits 4000 views were dropping the vi...</td>\n",
       "      <td>Wattz | #TalkAboutIt OUT NOW!</td>\n",
       "      <td>89203</td>\n",
       "      <td>1757</td>\n",
       "      <td>Norwich 🔰</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-30 13:20:12</td>\n",
       "      <td>#Global Views</td>\n",
       "      <td>Home_improvement</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT Fascinating statistics of my content global...</td>\n",
       "      <td>Wesley Pennock</td>\n",
       "      <td>333</td>\n",
       "      <td>61</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2020-01-29 21:16:00</td>\n",
       "      <td>#Global Views</td>\n",
       "      <td>Home_improvement</td>\n",
       "      <td>0.140625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets  \\\n",
       "0  Once this hits 4000 views were dropping the vi...   \n",
       "1  Once this hits 4000 views were dropping the vi...   \n",
       "2  RT Fascinating statistics of my content global...   \n",
       "3  Once this hits 4000 views were dropping the vi...   \n",
       "4  RT Fascinating statistics of my content global...   \n",
       "\n",
       "                            User User_statuses_count user_followers  \\\n",
       "0  Wattz | #TalkAboutIt OUT NOW!               89203           1757   \n",
       "1  Wattz | #TalkAboutIt OUT NOW!               89203           1757   \n",
       "2                 Wesley Pennock                 333             61   \n",
       "3  Wattz | #TalkAboutIt OUT NOW!               89203           1757   \n",
       "4                 Wesley Pennock                 333             61   \n",
       "\n",
       "     User_location User_verified fav_count rt_count           tweet_date  \\\n",
       "0       Norwich 🔰          False         0        0  2020-01-30 13:20:12   \n",
       "1       Norwich 🔰          False         0        0  2020-01-30 13:20:12   \n",
       "2  San Antonio, TX         False         0        9  2020-01-29 21:16:00   \n",
       "3       Norwich 🔰          False         0        0  2020-01-30 13:20:12   \n",
       "4  San Antonio, TX         False         0        9  2020-01-29 21:16:00   \n",
       "\n",
       "        Category  Product_Category  Sentiment_Polarity  \n",
       "0  #Global Views  Home_improvement            0.000000  \n",
       "1  #Global Views  Home_improvement            0.000000  \n",
       "2  #Global Views  Home_improvement            0.140625  \n",
       "3  #Global Views  Home_improvement            0.000000  \n",
       "4  #Global Views  Home_improvement            0.140625  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "df['Week_Date'] = df['tweet_date'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 2: For Time Series Visualization\n",
    "df_weekly=df.assign(\n",
    "    Re_Tweets_Weekly=df['rt_count'],\n",
    ").groupby('Week_Date').agg(dict(Re_Tweets_Weekly=len)).reset_index()\n",
    "\n",
    "df_weekly.sort_values(\"Week_Date\", axis = 0, ascending = True, \n",
    "                 inplace = True, na_position ='last') \n",
    "\n",
    "df_weekly.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datalab.context import Context\n",
    "import datalab.storage as storage\n",
    "import datalab.bigquery as bq\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import time\n",
    "from pandas.io import gbq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exporting Tables\n",
    "\n",
    "df.to_gbq(destination_table=\"Tweets_Data.Tweets_data\",project_id='fnmacc-esquires',if_exists='replace')#Main Tweets Table\n",
    "df_new_1.to_gbq(destination_table=\"Tweets_Data.Tweets_Summary\",project_id='fnmacc-esquires',if_exists='replace')# Summary Table\n",
    "df_weekly.to_gbq(destination_table=\"Tweets_Data.Weekly_Tweets\",project_id='fnmacc-esquires',if_exists='replace')# Weekly Table\n",
    "df_pos.to_gbq(destination_table=\"Tweets_Data.Top_Pos_Tweets\",project_id='fnmacc-esquires',if_exists='replace')#Positive Tweets\n",
    "df_neg.to_gbq(destination_table=\"Tweets_Data.Top_Neg_Tweets\",project_id='fnmacc-esquires',if_exists='replace')#Negative Tweets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
